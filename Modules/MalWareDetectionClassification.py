import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn import svm
from sklearn.cross_validation import cross_val_score
from sklearn.cross_validation import train_test_split
from sklearn import metrics
from sklearn import grid_search
from sklearn.preprocessing import Normalizer
import os
import sys
import time

def GetFileList(Directory):
    '''
    Get the list of file names (absolute path) in a directory

    :param String Directory: absolute path of a directory
    :return FileList: list of file names
    :rtype: List
    '''

    FileList = []
    for File in os.listdir(Directory):
        FileList.append(os.path.join(Directory, File))
    return FileList

def MyTokenizer (Str):
    return [S.strip() for S in Str.split()]

def Classification(MalwareCorpus, GoodwareCorpus, FeatureOption):
    '''
    Train a classifier for classifying malwares and goodwares using Support Vector Machine technique
    Compute the prediction accuracy and f1 score of the classifier

    :param String MalwareCorpus: absolute path of the malware corpus
    :param String GoodwareCorpus: absolute path of the goodware corpus
    :param String FeatureOption: tfidf or binary, specify how to construct the feature vector  
    '''

    # step 1: split all samples to training set and test set (3:1)
    AllMalSamples = GetFileList(MalwareCorpus)
    AllGoodSamples = GetFileList(GoodwareCorpus)
    print "Loaded samples"

    TrainSamples, TestSamples = train_test_split(AllMalSamples, test_size=0.25, random_state=42)
    TrainGoodSamples, TestGoodSamples = train_test_split(AllGoodSamples, test_size=0.25, random_state=42)
    print "train-test split done"


    # label malware as 1 and goodware as -1
    TrainMalLabels = np.ones(len(TrainSamples))
    TestMalLabels = np.ones(len(TestSamples))
    TrainGoodLabels = np.empty(len(TrainGoodSamples))
    TrainGoodLabels.fill(-1)
    TestGoodLabels = np.empty(len(TestGoodSamples))
    TestGoodLabels.fill(-1)


    TrainSamples.extend(TrainGoodSamples)
    TestSamples.extend(TestGoodSamples)
    
    TrainLabels = TrainMalLabels.tolist()
    TrainLabels.extend(TrainGoodLabels.tolist())
    TestLabels = TestMalLabels.tolist()
    TestLabels.extend(TestGoodLabels.tolist())
    print "Labels array - generated"

    # step 2: creating a TFIDF vector
    if(FeatureOption == 'tfidf'):
        #CVectorizer = CountVectorizer(input=u'filename', lowercase=False, token_pattern=u'[a-zA-Z,;]+')
        print "Gonna generate tfidf vectors"
        CVectorizer = CountVectorizer(input=u'filename', lowercase=False, token_pattern=None, tokenizer=MyTokenizer)
        TFIDFTransformer = TfidfTransformer()
        TrainDocsTermsFVs = CVectorizer.fit_transform(TrainSamples) 
        TestDocsTermsFVs = CVectorizer.transform(TestSamples)
        TrainFVs = TFIDFTransformer.fit_transform(TrainDocsTermsFVs)
        TestFVs = TFIDFTransformer.transform(TestDocsTermsFVs)
        print "tfidf vectors - generated"
        
    elif(FeatureOption == 'binary'):
        CVectorizer = CountVectorizer(input=u'filename', lowercase=False, token_pattern=u'[a-zA-Z,;]+', binary=True, dtype=np.float)
        normalizer = Normalizer()
        TrainDocsTermsFVs = CVectorizer.fit_transform(TrainSamples) 
        TestDocsTermsFVs = CVectorizer.transform(TestSamples)
        TrainFVs = normalizer.fit_transform(TrainDocsTermsFVs)
        TestFVs = normalizer.transform(TestDocsTermsFVs)


    # step 3: model selection through cross validation
    # assuming SVM is the only classifier we are gonna try, we will set the c parameter as follows.
    print "performing CV"
    Clf = grid_search.GridSearchCV(svm.LinearSVC(), {'C':[0.001, 0.01, 0.1, 1, 10, 100, 1000]}, cv=5, scoring = 'f1', n_jobs=10)
    BestModel = Clf.fit (TrainFVs, TrainLabels)
    print "CV done - model selected"
    # best model is chosen thro 5-fold cross validation and stored in the variable: BestModel

    # step 4: Evaluate the best model on test set
    PredictedLabels = BestModel.predict(TestFVs)
    Accuracy = np.mean(PredictedLabels == TestLabels)
    print "Test Set Accuracy = ", Accuracy
    print(metrics.classification_report(TestLabels, 
                PredictedLabels, target_names=['Goodware', 'Malware']))

def main(AndroguardHome, ApkDatasetDir, CFGDatasetDir, MalwareDirName, GoodwareDirName, ProcessNo, FeatureOption, GraphOption, Direct, Degree):
    '''
    Main function for malware detection classification

    :param String AndroguardHome: absolute path of the Androguard home directory
    :param String ApkDatasetDir: absolute path of the root directory of different catelogies of apks
    :param String CFGDatasetDir: absolute path of the CFG dataset
    :param String MalwareDirName: name of the malware directory in ApkDatasetDir
    :param String GoodwareDirName: name of the goodware directory in ApkDatasetDir
    :param int/String ProcessNo: number of processes scheduled for CFG string creation
    :param String FeatureOption: tf-idf or binary, specify how to construct the feature vector
    :param String GraphOption: none, CFG, iCFG
    :param String/boolean Direct: whether to treat iCFG as direct or indirected graph, only used when GraphOption is iCFG
    :param String/int Degree: Degree of neighbors to condider for calling and called node, only used when GraphOption is iCFG
    '''

    if (GraphOption == 'none'):
        print "=========== No WLKernel ============"
        GetCorpus = "python GetCorpus.py %s %s %s %s" %(AndroguardHome, ApkDatasetDir, CFGDatasetDir, ProcessNo)
        try:
            os.system(GetCorpus)
        except Exception as e:
            print "Fail to invoke GetCorpus."
            return

    elif (GraphOption == 'CFG'):
        print "=========== Using WLKernel and CFG ============="
        GetCorpusPlusNeighbors = "python GetCorpusPlusNeighbors.py %s %s %s %s" %(AndroguardHome, ApkDatasetDir, CFGDatasetDir, ProcessNo)
        try:
            os.system(GetCorpusPlusNeighbors)
        except Exception as e:
            print "Fail to invoke GetCorpusPlusNeighbors."
            return 

    elif (GraphOption == 'iCFG'):
        print "=========== Using WLKernel and iCFG ============="
        GetCorpusiCFG = "python GetCorpusiCFG.py %s %s %s %s %s %s" %(AndroguardHome, ApkDatasetDir, CFGDatasetDir, ProcessNo, Direct, Degree)
        try:
            os.system(GetCorpusiCFG)
        except Exception as e:
            print "Fail to invoke GetCorpusiCFG."
            return

    else:
        print "Parameter GraphOption can only be none, CFG or iCFG"
        return 

    Classification(os.path.join(CFGDatasetDir, MalwareDirName), os.path.join(CFGDatasetDir, GoodwareDirName), FeatureOption)

if __name__ == "__main__":
    TimeOutputPath = open("time.txt", 'a')
    print >>TimeOutputPath,"Program starts at: ",time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))
    TimeOutputPath.close()
    StartTime=time.time()
    main(sys.argv[1], sys.argv[2], sys.argv[3], sys.argv[4], sys.argv[5], sys.argv[6], sys.argv[7], sys.argv[8], sys.argv[9], sys.argv[10])
    EndTime=time.time()
    TimeOutputPath = open("time.txt", 'a')
    TimeOutputPath.write("Total Running Time: "+str(EndTime-StartTime)+' seconds\n')
    print >>TimeOutputPath,"Program ends at: ",time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))
    TimeOutputPath.close()

# main('/home/crazyconv/androguard',\
#     '/home/crazyconv/Desktop/Ureca/Malware_Detection/temp', \
#     '/home/crazyconv/Desktop/Ureca/Malware_Detection/temp_store2', \
#     'temp_bad', \
#     'temp_good', \
#     2,\
#     'tfidf', \
#     'iCFG', \
#     False,\
#     2)